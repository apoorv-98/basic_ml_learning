{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model weights from [data/model/weights.h5]....\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 512, None, 1)      0         \n",
      "_________________________________________________________________\n",
      "pad1 (ZeroPadding2D)         (None, 514, None, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 254, None, 96)     4800      \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 254, None, 96)     384       \n",
      "_________________________________________________________________\n",
      "relu1 (Activation)           (None, 254, None, 96)     0         \n",
      "_________________________________________________________________\n",
      "mpool1 (MaxPooling2D)        (None, 126, None, 96)     0         \n",
      "_________________________________________________________________\n",
      "pad2 (ZeroPadding2D)         (None, 128, None, 96)     0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 62, None, 256)     614656    \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 62, None, 256)     1024      \n",
      "_________________________________________________________________\n",
      "relu2 (Activation)           (None, 62, None, 256)     0         \n",
      "_________________________________________________________________\n",
      "mpool2 (MaxPooling2D)        (None, 30, None, 256)     0         \n",
      "_________________________________________________________________\n",
      "pad3 (ZeroPadding2D)         (None, 32, None, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 30, None, 384)     885120    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 30, None, 384)     1536      \n",
      "_________________________________________________________________\n",
      "relu3 (Activation)           (None, 30, None, 384)     0         \n",
      "_________________________________________________________________\n",
      "pad4 (ZeroPadding2D)         (None, 32, None, 384)     0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 30, None, 256)     884992    \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 30, None, 256)     1024      \n",
      "_________________________________________________________________\n",
      "relu4 (Activation)           (None, 30, None, 256)     0         \n",
      "_________________________________________________________________\n",
      "pad5 (ZeroPadding2D)         (None, 32, None, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 30, None, 256)     590080    \n",
      "_________________________________________________________________\n",
      "bn5 (BatchNormalization)     (None, 30, None, 256)     1024      \n",
      "_________________________________________________________________\n",
      "relu5 (Activation)           (None, 30, None, 256)     0         \n",
      "_________________________________________________________________\n",
      "mpool5 (MaxPooling2D)        (None, 9, None, 256)      0         \n",
      "_________________________________________________________________\n",
      "pad6 (ZeroPadding2D)         (None, 9, None, 256)      0         \n",
      "_________________________________________________________________\n",
      "fc6 (Conv2D)                 (None, 1, None, 4096)     9441280   \n",
      "_________________________________________________________________\n",
      "bn6 (BatchNormalization)     (None, 1, None, 4096)     16384     \n",
      "_________________________________________________________________\n",
      "relu6 (Activation)           (None, 1, None, 4096)     0         \n",
      "_________________________________________________________________\n",
      "gapool6 (GlobalAveragePoolin (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape6 (Reshape)           (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "pad7 (ZeroPadding2D)         (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "fc7 (Conv2D)                 (None, 1, 1, 1024)        4195328   \n",
      "_________________________________________________________________\n",
      "bn7 (BatchNormalization)     (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "relu7 (Activation)           (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "norm (Lambda)                (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "fc8 (Conv2D)                 (None, 1, 1, 1024)        1049600   \n",
      "=================================================================\n",
      "Total params: 17,691,328\n",
      "Trainable params: 17,678,592\n",
      "Non-trainable params: 12,736\n",
      "_________________________________________________________________\n",
      "Processing enroll samples....\n",
      "Processing test samples....\n",
      "Comparing test samples against enroll samples....\n",
      "speaker         1         1         2         3         4\n",
      "0        0.161717  0.472573  0.736485  1.298641  0.842463\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist, euclidean, cosine\n",
    "from glob import glob\n",
    "\n",
    "from model import vggvox_model\n",
    "from wav_reader import get_fft_spectrum\n",
    "import constants as c\n",
    "\n",
    "\n",
    "def build_buckets(max_sec, step_sec, frame_step):\n",
    "\tbuckets = {}\n",
    "\tframes_per_sec = int(1/frame_step)\n",
    "\tend_frame = int(max_sec*frames_per_sec)\n",
    "\tstep_frame = int(step_sec*frames_per_sec)\n",
    "\tfor i in range(0, end_frame+1, step_frame):\n",
    "\t\ts = i\n",
    "\t\ts = np.floor((s-7+2)/2) + 1  # conv1\n",
    "\t\ts = np.floor((s-3)/2) + 1  # mpool1\n",
    "\t\ts = np.floor((s-5+2)/2) + 1  # conv2\n",
    "\t\ts = np.floor((s-3)/2) + 1  # mpool2\n",
    "\t\ts = np.floor((s-3+2)/1) + 1  # conv3\n",
    "\t\ts = np.floor((s-3+2)/1) + 1  # conv4\n",
    "\t\ts = np.floor((s-3+2)/1) + 1  # conv5\n",
    "\t\ts = np.floor((s-3)/2) + 1  # mpool5\n",
    "\t\ts = np.floor((s-1)/1) + 1  # fc6\n",
    "\t\tif s > 0:\n",
    "\t\t\tbuckets[i] = int(s)\n",
    "\treturn buckets\n",
    "\n",
    "\n",
    "# def get_embedding(model, wav_file, max_sec):\n",
    "# \tbuckets = build_buckets(max_sec, c.BUCKET_STEP, c.FRAME_STEP)\n",
    "# \tsignal = get_fft_spectrum(wav_file, buckets)\n",
    "# \tembedding = np.squeeze(model.predict(signal.reshape(1,*signal.shape,1)))\n",
    "# \treturn embedding\n",
    "\n",
    "\n",
    "# def get_embedding_batch(model, wav_files, max_sec):\n",
    "# \treturn [ get_embedding(model, wav_file, max_sec) for wav_file\n",
    "\n",
    "\n",
    "def get_embeddings_from_list_file(model, list_file, max_sec):\n",
    "\tbuckets = build_buckets(max_sec, c.BUCKET_STEP, c.FRAME_STEP)\n",
    "\tresult = pd.read_csv(list_file, delimiter=\",\")\n",
    "\tresult['features'] = result['filename'].apply(lambda x: get_fft_spectrum(x, buckets))\n",
    "\tresult['embedding'] = result['features'].apply(lambda x: np.squeeze(model.predict(x.reshape(1,*x.shape,1))))\n",
    "\treturn result[['filename','speaker','embedding']]\n",
    "\n",
    "\n",
    "def get_id_result():\n",
    "    print(\"Loading model weights from [{}]....\".format(c.WEIGHTS_FILE))\n",
    "    model = vggvox_model()\n",
    "    model.load_weights(c.WEIGHTS_FILE)\n",
    "    model.summary()\n",
    "    print(\"Processing enroll samples....\")\n",
    "    enroll_result = get_embeddings_from_list_file(model, c.ENROLL_LIST_FILE, c.MAX_SEC)\n",
    "    enroll_embs = np.array([emb.tolist() for emb in enroll_result['embedding']])\n",
    "    speakers = enroll_result['speaker']\n",
    "    print(\"Processing test samples....\")\n",
    "    test_result = get_embeddings_from_list_file(model, c.TEST_LIST_FILE, c.MAX_SEC)\n",
    "    test_embs = np.array([emb.tolist() for emb in test_result['embedding']])\n",
    "    print(\"Comparing test samples against enroll samples....\")\n",
    "    distances = pd.DataFrame(cdist(test_embs, enroll_embs, metric=c.COST_METRIC),columns=speakers)\n",
    "    print(distances)\n",
    "    dist_t=pd.DataFrame.transpose(distances)\n",
    "    dist_t=np.array(dist_t)\n",
    "    k=np.amin(dist_t,axis=0)\n",
    "    if(k>.25):\n",
    "        print(\"unauthorized user................\")\n",
    "    else:\n",
    "        scores = pd.read_csv(c.TEST_LIST_FILE, delimiter=\",\",header=0,names=['test_file','test_speaker'])\n",
    "        scores = pd.concat([scores, distances],axis=1)\n",
    "        speaker_token = scores[speakers].idxmin(axis=1)\n",
    "        print(speaker_token[0])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tget_id_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: sophora smart India hackathon be trying to build a chatbot based on Deep learning model for the purpose of this\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\"\"\"# convert mp3 file to wav                                                       \n",
    "sound = AudioSegment.from_mp3(\"sample.mp3\")\n",
    "sound.export(\"sample.wav\", format=\"wav\")\"\"\"\n",
    "\n",
    "\n",
    "# transcribe audio file                                                         \n",
    "AUDIO_FILE = \"sample.wav\"\n",
    "\n",
    "# use the audio file as the audio source                                        \n",
    "r = sr.Recognizer()\n",
    "a=[]\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "        audio = r.record(source)  # read the entire audio file \n",
    "        a=r.recognize_google(audio)\n",
    "\n",
    "        print(\"Transcription: \" + a)\n",
    "        \n",
    "        with open('sample.txt', 'w') as f:\n",
    "            for item in a:\n",
    "                f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
